{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 问题描述：对于原始字符集“AB……Z”，根据前面的字符预测下一个字符。\n",
    "2. 思路：首先定义问题的输入输出，对于序列问题，每一步的输入组成的序列为模型的输入，每一步的输出组成的序列为模型的输出；然后，必须将语义输入输出转换成计算机能够处理的数值，这个过程中用一个字典映射作辅助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window=3时理想的效果：\n",
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n",
      "total samples: 23\n"
     ]
    }
   ],
   "source": [
    "raw_data = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "window = 3                  # 相当与n-gram模型中的窗口大小n\n",
    "char_to_int = dict((c,i) for i,c in enumerate(raw_data))  # 将输入转换成数值（模型只能计算数值）\n",
    "int_to_char = dict((i,c) for i,c in enumerate(raw_data))  # 方便将计算结果转换成语义结果\n",
    "x_data = []\n",
    "y_data = []\n",
    "print(\"window=%s时理想的效果：\" % window)\n",
    "for i in range(0, len(raw_data)-window, 1):\n",
    "    seq_in = raw_data[i:i+window]\n",
    "    seq_out = raw_data[i+window]\n",
    "    x_data.append([char_to_int[char] for char in seq_in]) # 将输入转换成数值\n",
    "    y_data.append(char_to_int[seq_out])\n",
    "    print(seq_in,'->',seq_out)\n",
    "print(\"total samples: %s\" % len(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(x_data, (len(x_data), window, 1)) # 将数值输入转换成（sample，time-step，feature）形式送入LSTM处理。\n",
    "x = x/len(raw_data)\n",
    "y = np_utils.to_categorical(y_data)              # 对y_data进行one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accurancy: 100.00\n",
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> E\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> W\n",
      "['U', 'V', 'W'] -> X\n",
      "['V', 'W', 'X'] -> Y\n",
      "['W', 'X', 'Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(x.shape[1], x.shape[2])))\n",
    "lstm.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "lstm.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "lstm.fit(x, y, batch_size=1, epochs=500, verbose=0)\n",
    "score = lstm.evaluate(x, y, verbose=0)\n",
    "print(\"train accurancy: %.2f\" % (score[1]*100))\n",
    "for term in x_data:\n",
    "    sample = np.reshape(term, (1,len(term),1))\n",
    "    sample = sample/float(len(raw_data))\n",
    "    prediction = lstm.predict(sample, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in term]\n",
    "    print(seq_in,'->',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
