{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 问题描述：对于原始字符集“AB……Z”，根据前面的字符预测下一个字符。\n",
    "2. 思路：首先定义问题的输入输出，对于序列问题，每一步的输入组成的序列为模型的输入，每一步的输出组成的序列为模型的输出；然后，必须将语义输入输出转换成计算机能够处理的数值，这个过程中用一个字典映射作辅助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window=3时理想的效果：\n",
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n",
      "total samples: 23\n"
     ]
    }
   ],
   "source": [
    "raw_data = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "window = 3                  # 相当与n-gram模型中的窗口大小n\n",
    "char_to_int = dict((c,i) for i,c in enumerate(raw_data))  # 将输入转换成数值（模型只能计算数值）\n",
    "int_to_char = dict((i,c) for i,c in enumerate(raw_data))  # 方便将计算结果转换成语义结果\n",
    "x_data = []\n",
    "y_data = []\n",
    "print(\"window=%s时理想的效果：\" % window)\n",
    "for i in range(0, len(raw_data)-window, 1):\n",
    "    seq_in = raw_data[i:i+window]\n",
    "    seq_out = raw_data[i+window]\n",
    "    x_data.append([char_to_int[char] for char in seq_in]) # 将输入转换成数值\n",
    "    y_data.append(char_to_int[seq_out])\n",
    "    print(seq_in,'->',seq_out)\n",
    "print(\"total samples: %s\" % len(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 从数据集中抽取了(DEF,G) (HIJ,K) (LMN,0) (PQR,S) (TUV,W)五条数据用作测试集，剩下的作为训练集。保证所有字目都是模型见过的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples count: 18, test samples count: 5\n",
      "test sample: [[[ 0.11538462]\n",
      "  [ 0.15384615]\n",
      "  [ 0.19230769]]\n",
      "\n",
      " [[ 0.26923077]\n",
      "  [ 0.30769231]\n",
      "  [ 0.34615385]]\n",
      "\n",
      " [[ 0.42307692]\n",
      "  [ 0.46153846]\n",
      "  [ 0.5       ]]\n",
      "\n",
      " [[ 0.57692308]\n",
      "  [ 0.61538462]\n",
      "  [ 0.65384615]]\n",
      "\n",
      " [[ 0.73076923]\n",
      "  [ 0.76923077]\n",
      "  [ 0.80769231]]] [[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(x_data, (len(x_data), window, 1)) # 将数值输入转换成（sample，time-step，feature）形式送入LSTM处理。\n",
    "x = x/len(raw_data)\n",
    "y = np_utils.to_categorical(y_data)              # 对y_data进行one-hot编码\n",
    "x_test = [x[i] for i in (3,7,11,15,19)]   # 取最后5条sample为测试集，剩下的用作训练\n",
    "y_test = [y[i] for i in (3,7,11,15,19)]\n",
    "# x_train = [i for i in x if i not in x_test]   \n",
    "# y_train = [i for i in y if i not in y_test]\n",
    "x_train = [x[i] for i in (0,1,2,4,5,6,8,9,10,12,13,14,16,17,18,20,21,22)]\n",
    "y_train = [y[i] for i in (0,1,2,4,5,6,8,9,10,12,13,14,16,17,18,20,21,22)]\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"train samples count: %s, test samples count: %s\"% (len(x_train),len(x_test)))\n",
    "print(\"test sample:\",x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么在测试准确率为0？为什么不能根据规律推测？\n",
    "* 是不是训练集的知识和测试集的知识有断层（模型都没有见过测试集中的字母'V','W','X','Y','Z'）？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accurancy: 100.00\n",
      "['D', 'E', 'F'] -> H\n",
      "['H', 'I', 'J'] -> J\n",
      "['L', 'M', 'N'] -> N\n",
      "['P', 'Q', 'R'] -> R\n",
      "['T', 'U', 'V'] -> V\n",
      "test accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "lstm.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "lstm.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "lstm.fit(x_train, y_train, batch_size=1, epochs=500, verbose=0)\n",
    "score = lstm.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"train accurancy: %.2f\" % (score[1]*100))\n",
    "for term in [x_data[i] for i in (3,7,11,15,19)]:\n",
    "    sample = np.reshape(term, (1,len(term),1))\n",
    "    sample = sample/float(len(raw_data))\n",
    "    prediction = lstm.predict(sample, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in term]\n",
    "    print(seq_in,'->',result)\n",
    "score2 = lstm.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"test accuracy: %.2f\" % (score2[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
